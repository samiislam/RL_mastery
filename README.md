# 🧠 Reinforcement Learning Roadmap: Zero to Expert in 90 Days

> Bulletproof, no-fluff RL roadmap with milestones, tools, and projects — faster than any course or YouTube video.

---

## 📅 Timeline Overview

| Phase         | Days     | Focus                          | Milestone Example                         |
|---------------|----------|--------------------------------|-------------------------------------------|
| Phase 0       | 0        | Setup                          | Python, Gymnasium, GPU ready              |
| Phase 1       | 1–14     | RL Basics                      | Tabular Q-learning                        |
| Phase 2       | 15–40    | Deep RL                        | PPO on LunarLander                        |
| Phase 3       | 41–70    | Advanced RL                    | SAC on BipedalWalker                      |
| Phase 4       | 71–85    | Research/Custom Envs           | Custom Gymnasium env + paper reproduction |
| Phase 5       | 86–90+   | Portfolio & Mastery            | Blog, GitHub, real-world project          |

---

## 🚀 Phase 0: Setup & Mindset (Day 0)

- [ ] Python 3.10+, VSCode or Jupyter
- [ ] Install PyTorch, Gymnasium, Stable-Baselines3
- [ ] Get GPU access (Google Colab Pro / local GPU)

```bash
pip install torch gymnasium[box2d] stable-baselines3[extra] wandb
```

---

## 📘 Phase 1: RL Fundamentals (Days 1–14)

- [ ] ✅ Write MDP simulator
- [ ] ✅ Tabular Q-learning from scratch
- [ ] ✅ Solve FrozenLake-v1

**Resources:**
- Sutton & Barto Book (Ch. 1–6)
- David Silver Lectures (1–4)

📁 `projects/phase1_q_learning/`

---

## 🧠 Phase 2: Deep RL (Days 15–40)

- [ ] ✅ DQN with experience replay
- [ ] ✅ Policy Gradient (REINFORCE)
- [ ] ✅ PPO on LunarLander-v2

**Resources:**
- DQN Paper (Mnih et al. 2015)
- PPO Paper (Schulman et al. 2017)

📁 `projects/phase2_dqn_ppo/`

---

## 🔬 Phase 3: Advanced RL (Days 41–70)

- [ ] ✅ SAC on Pendulum/BipedalWalker
- [ ] ✅ TD3 implementation
- [ ] ✅ Multi-agent gridworld w/ PettingZoo

**Resources:**
- "Deep RL Hands-On" Book (Ch. 7–17)
- Lilian Weng’s RL Blog Series

📁 `projects/phase3_sac_td3_multiagent/`

---

## 🧪 Phase 4: Research & Custom Envs (Days 71–85)

- [ ] ✅ Design your own Gymnasium environment
- [ ] ✅ Reimplement RL paper from scratch

**Resources:**
- Gymnasium Custom Env Guide
- Arxiv-Sanity + PapersWithCode

📁 `projects/phase4_custom_envs/`

---

## 🧑‍🔬 Phase 5: Portfolio & Mastery (Days 86–90+)

- [ ] ✅ Build RL project with real-world relevance
- [ ] ✅ Write blog or tutorial
- [ ] ✅ Push everything to GitHub + Colab

**Ideas:**
- RL for Neural Architecture Search
- RL in Finance or Robotics Sim
- Train on VizDoom / Unity ML Agents

📁 `projects/phase5_portfolio/`

---

## 📚 Tools & Libraries

- [Gymnasium](https://gymnasium.farama.org/)
- [Stable-Baselines3](https://github.com/DLR-RM/stable-baselines3)
- [PettingZoo](https://www.pettingzoo.ml/)
- [CleanRL](https://github.com/vwxyzjn/cleanrl)
- [Weights & Biases](https://wandb.ai/)

---

## 🌐 Optional: Stay Connected

- [OpenAI Discord](https://discord.gg/openai)
- [HuggingFace RL](https://huggingface.co/blog/deep-rl-dqn)
- [RL Subreddit](https://reddit.com/r/reinforcementlearning)

---

## ✅ How to Use This Repo

- Use one folder per phase.
- Document every experiment with results (videos/plots).
- Keep a markdown log of what you learn weekly.
- Push code, write README, publish insights.

---

Happy training! ⚡

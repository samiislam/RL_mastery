{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dae9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from scipy.stats import poisson\n",
    "\n",
    "def row_col_to_index(i, j):\n",
    "    return i * 21 + j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21cd2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 4x4 gridworld\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class LocationGridCell():\n",
    "    #            cars_in_location1, cars_in_location2\n",
    "    state: tuple[int,               int]                = (0, 0)\n",
    "    value: float = 0.0\n",
    "    optimal_action: int = 0 # (-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5)\n",
    "\n",
    "# 1.\n",
    "# Initialization\n",
    "# V(s) ∈ R and π(s) ∈ A(s) arbitraritly for all s ∈ S [Note: I am setting it all to 0 and all actions are equally optimal]\n",
    "\n",
    "\n",
    "num_cars_in_locations = []\n",
    "\n",
    "# Create a 21x21 grid (441 cells) representing states from (0,0) to (20,20)\n",
    "# Each state (i, j) represents (cars_at_location1, cars_at_location2)\n",
    "# Index = i * 21 + j\n",
    "\n",
    "for i in range(21):  # cars_at_location1: 0 to 20\n",
    "    for j in range(21):  # cars_at_location2: 0 to 20\n",
    "        index = row_col_to_index(i, j)\n",
    "        # Initialize next_states as placeholder (same state for all actions)\n",
    "        # Update these based on your transition logic\n",
    "        num_cars_in_locations.append(LocationGridCell((i, j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dab5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_state_value(loc1: int, loc2: int) -> float:\n",
    "    next_state_index = row_col_to_index(loc1, loc2)\n",
    "    value_next_state = num_cars_in_locations[next_state_index].value\n",
    "    return value_next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1bab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n",
    "# Policy Evaluation\n",
    "# Loop:\n",
    "#   Δ ← 0\n",
    "#   Loop for each s ∈ S:\n",
    "#     v ← V(s)\n",
    "#     V(s) ← ∑_{s´,r} p(s´, r | s, π(s))[r + γV(s´)]\n",
    "#     Δ ← max(Δ, |v - V(s)|)\n",
    "# until Δ < θ (a small positive number determining the accuracy of estimation)\n",
    "\n",
    "def compute_state_value(location_gridcell: LocationGridCell) -> float:\n",
    "    gamma = 0.9\n",
    "    num_req_ret_to_consider = 11\n",
    "    state_value = 0.0\n",
    "\n",
    "    net_move_from_day_before = location_gridcell.optimal_action # This can be (-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5)\n",
    "\n",
    "    loc1 = location_gridcell.state[0]\n",
    "    loc1_today = loc1 - net_move_from_day_before\n",
    "    loc2 = location_gridcell.state[1]\n",
    "    loc2_today = loc2 + net_move_from_day_before\n",
    "\n",
    "    # Make sure we don't go negative\n",
    "    if loc1_today > 0 and loc2_today > 0:\n",
    "        # The main question to ask here is: What affects the next state?\n",
    "        # In this case it is request and return for each of our two locations\n",
    "        #\n",
    "        # Moreover the transition from one state to the next also depends\n",
    "        # on how many cars are available at each location after the request\n",
    "        # and return for a day\n",
    "        for rq1 in range(num_req_ret_to_consider):\n",
    "            for re1 in range(num_req_ret_to_consider):\n",
    "                for rq2 in range(num_req_ret_to_consider):\n",
    "                    for re2 in range(num_req_ret_to_consider):\n",
    "\n",
    "                        transition_probability = poisson.pmf(rq1, 3) * poisson.pmf(re1, 3) * poisson.pmf(rq2, 4) * poisson.pmf(re2, 2)\n",
    "\n",
    "                        actual_rentals_loc1 = min(rq1, loc1_today)\n",
    "                        actual_rentals_loc2 = min(rq2, loc2_today)\n",
    "\n",
    "                        reward = (-2 * abs(net_move_from_day_before)) + (10 * actual_rentals_loc1) + (10 * actual_rentals_loc2)\n",
    "\n",
    "                        new_loc1 = max(0, min(loc1_today - actual_rentals_loc1 + re1, 20))\n",
    "                        new_loc2 = max(0, min(loc2_today - actual_rentals_loc2 + re2, 20))\n",
    "\n",
    "                        state_value += transition_probability * (reward + gamma * get_next_state_value(new_loc1, new_loc2))\n",
    "    \n",
    "    return state_value\n",
    "    \n",
    "\n",
    "def run_policy_evaluation():\n",
    "    theta = 0.01\n",
    "    iteration = 1\n",
    "\n",
    "    while True:\n",
    "        delta = 0.0\n",
    "        location_gridcell: LocationGridCell\n",
    "\n",
    "        for location_gridcell in num_cars_in_locations:\n",
    "            v  = location_gridcell.value\n",
    "            location_gridcell.value = compute_state_value(location_gridcell)\n",
    "            delta = max(delta, abs(v - location_gridcell.value))\n",
    "        \n",
    "        print(f\"After iteration {iteration} - delta = {delta}\")\n",
    "\n",
    "        if delta < theta:\n",
    "            print(f\"Converged after iteration {iteration}\")\n",
    "            break\n",
    "\n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e114fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_policy_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff0e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_improved_policy_indices(location_gridcell: LocationGridCell, actions: ndarray[int]) -> ndarray[int]:\n",
    "    gamma = 0.9\n",
    "    num_req_ret_to_consider = 11\n",
    "    \n",
    "    # The action(s) for which V(s) has the highest value - total #actions = 11 (-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5)\n",
    "    value_states = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dtype=float)\n",
    "\n",
    "    for i, a in enumerate(actions):\n",
    "        net_move_from_day_before = a\n",
    "\n",
    "        loc1 = location_gridcell.state[0]\n",
    "        loc1_today = loc1 - net_move_from_day_before\n",
    "        loc2 = location_gridcell.state[1]\n",
    "        loc2_today = loc2 + net_move_from_day_before\n",
    "\n",
    "        # Make sure we don't go negative\n",
    "        if loc1_today < 0 or loc2_today < 0:\n",
    "            value_states[i] = float('-inf')\n",
    "            continue  # Skip this invalid scenario\n",
    "        \n",
    "        state_value = 0.0\n",
    "\n",
    "        for rq1 in range(num_req_ret_to_consider):\n",
    "            for re1 in range(num_req_ret_to_consider):\n",
    "                for rq2 in range(num_req_ret_to_consider):\n",
    "                    for re2 in range(num_req_ret_to_consider):\n",
    "\n",
    "                        transition_probability = poisson.pmf(rq1, 3) * poisson.pmf(re1, 3) * poisson.pmf(rq2, 4) * poisson.pmf(re2, 2)\n",
    "\n",
    "                        actual_rentals_loc1 = min(rq1, loc1_today)\n",
    "                        actual_rentals_loc2 = min(rq2, loc2_today)\n",
    "\n",
    "                        reward = (-2 * abs(net_move_from_day_before)) + (10 * actual_rentals_loc1) + (10 * actual_rentals_loc2)\n",
    "\n",
    "                        new_loc1 = max(0, min(loc1_today - actual_rentals_loc1 + re1, 20))\n",
    "                        new_loc2 = max(0, min(loc2_today - actual_rentals_loc2 + re2, 20))\n",
    "\n",
    "                        state_value += transition_probability * (reward + gamma * get_next_state_value(new_loc1, new_loc2))\n",
    "\n",
    "        value_states[i] = state_value\n",
    "\n",
    "    max_values = np.max(value_states)\n",
    "    ties: ndarray[int] = np.flatnonzero(value_states == max_values)\n",
    "    return ties\n",
    "    \n",
    "\n",
    "# 3.\n",
    "# Policy Improvement\n",
    "# policy-stable ← true\n",
    "# Loop for each s ∈ S:\n",
    "#   old-action ← π(s)\n",
    "#   π(s) ← argmax_{a} ∑_{s`,r} p(s´, r | s, a)[r + γV(s´)]\n",
    "#   If old-action ≠ π(s), then policy-stable ← false\n",
    "# If policy-stable, then stop and return V ≈ v_* and π ≈ π_*; else go to 2\n",
    "\n",
    "def run_policy_improvement() -> bool:\n",
    "    policy_stable = True\n",
    "    location_gridcell: LocationGridCell\n",
    "\n",
    "    actions = np.array([-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5], dtype=int)\n",
    "\n",
    "    for location_gridcell in num_cars_in_locations:\n",
    "        old_optimal_action = location_gridcell.optimal_action\n",
    "\n",
    "        ties = compute_improved_policy_indices(location_gridcell, actions)\n",
    "        selected_actions = actions[ties]\n",
    "\n",
    "        if old_optimal_action in selected_actions:\n",
    "            location_gridcell.optimal_action = old_optimal_action\n",
    "        else:\n",
    "            location_gridcell.optimal_action = np.random.choice(selected_actions)\n",
    "\n",
    "\n",
    "        if old_optimal_action != location_gridcell.optimal_action:\n",
    "            policy_stable = False\n",
    "            \n",
    "\n",
    "    return policy_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26280fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_stable = False\n",
    "\n",
    "while not policy_stable:\n",
    "    run_policy_evaluation()\n",
    "    policy_stable = run_policy_improvement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45818e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grid_world_optimal_policy():\n",
    "    direction = ['↑', '→', '↓', '←']\n",
    "    gridworld_rep = np.array(['0'] * 441)  # 21x21 = 441 cells\n",
    "    gridcell: LocationGridCell\n",
    "    for gridcell in num_cars_in_locations:\n",
    "        gridworld_rep[gridcell.index] = direction[gridcell.optimal_action]\n",
    "\n",
    "    print(gridworld_rep.reshape(21, 21))\n",
    "\n",
    "def print_grid_world_value_states():\n",
    "    gridworld_rep = np.array([0.0] * 441)  # 21x21 = 441 cells\n",
    "    gridcell: LocationGridCell\n",
    "    for gridcell in num_cars_in_locations:\n",
    "        gridworld_rep[gridcell.index] = gridcell.value\n",
    "    print(gridworld_rep.reshape(21, 21))\n",
    "\n",
    "print_grid_world_optimal_policy()\n",
    "print_grid_world_value_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4aeaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.array([-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5])\n",
    "ties = np.array([1, 5, 9])\n",
    "\n",
    "for i, a in enumerate(actions):\n",
    "    print(f'{i}:{a}')\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "selected_actions = actions[ties]\n",
    "\n",
    "for a in selected_actions:\n",
    "    print(f'{a}')\n",
    "\n",
    "test = np.random.choice(selected_actions)\n",
    "print(test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL_mastery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
